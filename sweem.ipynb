{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWEEM Model Implementation\n",
    "\n",
    "This file is used to illustrate the preprocessing, training, and evaluation \n",
    "stages of our model. Comments and more information will be provided per section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Here we load in the data and establish our train-test split. We also set up dataloaders\n",
    "for us to be able to properly use the data within our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_data = pd.read_csv('./Data/Multiple/train.csv')\n",
    "test_data = pd.read_csv('./Data/Multiple/test.csv')\n",
    "\n",
    "## Training Data\n",
    "rna_train = train_data.columns[:2708]                       # 2708 rna\n",
    "scna_train = train_data.columns[2708:5404]                  # 2696 scna\n",
    "mutation_train = train_data.columns[5404:5591]              # 187 mutation\n",
    "methy_train = train_data.columns[5591:7957]                 # 2366 methy\n",
    "target_train = train_data.columns[-3:]                      # 3 target\n",
    "\n",
    "## Testing Data\n",
    "rna_test = test_data.columns[:2708]                         # 2708 rna\n",
    "scna_test = test_data.columns[2708:5404]                    # 2696 scna\n",
    "mutation_test = test_data.columns[5404:5591]                # 187 mutation\n",
    "methy_test = test_data.columns[5591:7957]                   # 2366 methy\n",
    "target_test = test_data.columns[-3:]                        # 3 target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape:  (380, 7961)\n",
      "Testing Data Shape:  (48, 7961)\n",
      "\n",
      "RNA Labels:         ['ST3GAL2_rna', 'ELOVL1_rna'] ... ['TK2_rna', 'DHODH_rna']\n",
      "SCNA Labels:        ['ST3GAL2_scna', 'ELOVL1_scna'] ... ['TK2_scna', 'DHODH_scna']\n",
      "Mutation Labels:    ['ABCG4_mutation', 'DAPK1_mutation'] ... ['CDH4_mutation', 'ACSL4_mutation']\n",
      "Methylation Labels: ['ST3GAL2_methy', 'ELOVL1_methy'] ... ['PRKCQ_methy', 'TK2_methy']\n",
      "Target Labels:      ['SAMPLE_ID', 'OS_MONTHS', 'OS_EVENT']\n"
     ]
    }
   ],
   "source": [
    "### Sanity Checks on Data\n",
    "\n",
    "# Data Shapes; should have same number of features\n",
    "print('Training Data Shape: ', train_data.shape)    # (380, 7961)\n",
    "print('Testing Data Shape: ', test_data.shape)      # (48 , 7961)\n",
    "print()\n",
    "\n",
    "# Check header information\n",
    "print(f\"RNA Labels:         {list(train_data.columns[0:2])} ... {list(train_data.columns[2706:2708])}\")\n",
    "print(f\"SCNA Labels:        {list(train_data.columns[2708:2710])} ... {list(train_data.columns[5402:5404])}\")\n",
    "print(f\"Mutation Labels:    {list(train_data.columns[5404:5406])} ... {list(train_data.columns[5589:5591])}\")\n",
    "print(f\"Methylation Labels: {list(train_data.columns[5591:5593])} ... {list(train_data.columns[7955:7957])}\")\n",
    "print(f\"Target Labels:      {list(train_data.columns[-3:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RIGHT NOW, WE ONLY CARE ABOUT OS_MONTHS, WHICH IS THE SECOND TO LAST COLUMN\n",
    "\n",
    "# Split the data into train and validation sets.\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(\n",
    "    train_data.iloc[:, :-3], train_data.iloc[:, -2], test_size=0.2, random_state=42)\n",
    "\n",
    "test_features, test_labels = test_data.iloc[:, :-3], test_data.iloc[:, -2]\n",
    "\n",
    "# Create Tensor datasets\n",
    "train_dataset = TensorDataset(torch.tensor(train_features.values), torch.tensor(train_labels.values))\n",
    "val_dataset   = TensorDataset(torch.tensor(val_features.values),   torch.tensor(val_labels.values))\n",
    "test_dataset  = TensorDataset(torch.tensor(test_features.values),  torch.tensor(test_labels.values))\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Self-Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import SelfAttentionModel \n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "\n",
    "model = SelfAttentionModel(train_dataset.size()[1], 64, 64)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on\", device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training Loop\n",
    "num_epochs = 10\n",
    "epoch_train_losses = []\n",
    "epoch_val_losses   = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_train_loss = 0\n",
    "    epoch_val_loss   = 0\n",
    "    print(f\"Epoch {epoch + 1} training:\")\n",
    "    progress_bar = tqdm(range(len(train_dataloader)))\n",
    "\n",
    "    model.train()\n",
    "    ## Training\n",
    "    for (batchX, batchY) in train_dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(batchX.to(device))\n",
    "\n",
    "        # Backward pass\n",
    "        loss = criterion(outputs, batchY.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        epoch_train_loss += loss.item()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    model.eval()\n",
    "    ## Validation\n",
    "    with torch.no_grad():\n",
    "        for (batchX, batchY) in val_dataloader:\n",
    "            outputs = model(batchX.to(device))\n",
    "            loss = criterion(outputs, batchY.to(device))\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "    # Save and print losses\n",
    "    epoch_train_loss /= len(train_dataloader)\n",
    "    epoch_val_loss /= len(val_dataloader)\n",
    "    epoch_train_losses.append(epoch_train_loss)\n",
    "    epoch_val_losses.append(epoch_val_loss)\n",
    "    print(f\"Epoch {epoch + 1} training loss: {epoch_train_loss}\")\n",
    "    print(f\"Epoch {epoch + 1} validation loss: {epoch_val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing/Evaluation Loop\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for (batchX, batchY) in test_dataloader:\n",
    "        outputs = model(batchX.to(device))\n",
    "        loss = criterion(outputs, batchY.to(device))\n",
    "        test_loss += loss.item()\n",
    "\n",
    "print(f\"Test loss: {test_loss / len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
